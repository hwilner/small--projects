{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm7hH_nfRZXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56aogcfsTfMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dtree:\n",
        "  def __init__(self, k=None, max_depth=None):\n",
        "    ''' initilize class of type representing desion tree\n",
        "    k- minimum size of a perent node\n",
        "    max_depth-  maxsimal number for how many lyers of perent node will be used '''\n",
        "    self.k=k\n",
        "    self.depth= max_depth\n",
        "    self.root=()\n",
        "    \n",
        "    \n",
        "    \n",
        "  def fit (self, data, labels):\n",
        "    ''' generting a tree represting data '''\n",
        "    \n",
        "    labeled_data= self.feat_engeniring(data, labels)\n",
        "    \n",
        "    self.root=decision_tree(labeled_data,self.k, self.depth)\n",
        "    return self\n",
        "    \n",
        "        \n",
        "  def feat_engeniring(self,data, labels):\n",
        "    '''the function take on data and labels and convert them to numeric type data in order to create treshhold, and keep it as labels to predict'''\n",
        "#     s=set(list(data))\n",
        "#     l=list(range(len(s)))\n",
        "#     self.labels=dict( zip(  list[s],l,)) # turning all labels to random float keys \n",
        "    \n",
        "#     body=np.array([np.array([not_string(i.strip('\\n'))[1] for i in row]) for row in data ])\n",
        "    \n",
        "#     n_labels=np.array(list[map(lambda item: self.labels[a] ),labels ])\n",
        "    \n",
        "    \n",
        "#     return np.vstack((n_labels, body))\n",
        "    return np.vstack((labels, data))\n",
        "      # deal with non float labels data later\n",
        "    \n",
        "#   def not_string(self,a,log=None):\n",
        "#     ''' the functiom acepet an object and check if it a numerical or eqvivallent of type sting in base10 , it can print all filed log to log file\n",
        "#     args:\n",
        "#       a-object of any type\n",
        "#       log- file to  print to, defult -None\n",
        "\n",
        "#       out:\n",
        "#         tuple made of:\n",
        "#           flag- can be converted- bool type\n",
        "#           n- number in int/float/compex val in that order\n",
        "\n",
        "#       '''\n",
        "#     flag=True\n",
        "\n",
        "#     while flag:\n",
        "#       try: \n",
        "#         n=int(a) \n",
        "#       except ValueError:\n",
        "#         try :\n",
        "#           n=float(a)\n",
        "#         except  ValueError:\n",
        "#           try:\n",
        "#             n=complex(a)\n",
        "#           except ValueError:\n",
        "#             p=\"     I don't deal with any number that is not decimal\"\n",
        "#             flag=False\n",
        "#       finally:\n",
        "#         return flag,n\n",
        "\n",
        "\n",
        "    \n",
        "     \n",
        "    \n",
        "    \n",
        "    \n",
        "  def predict (self, data):\n",
        "    ''' prdicting label for data '''\n",
        "    labeled=[self.labels.get(binary_search_sheker(d)[0] ) for d in data]\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  def decision_tree (data, k, perent_h=None, depth=None):\n",
        "  ## add ability to split and join data\n",
        "  \n",
        "    if perent_h is None:\n",
        "      perent_h=shanon_ent(data[data[:,0]==1], data[data[:,0]==0])\n",
        "      #log(11,perent_h)\n",
        "    corrent_size=len(data)\n",
        "\n",
        "    if depth is None:\n",
        "\n",
        "      if (corrent_size>k) and (perent_h>0) :\n",
        "        col,treshold, new_en =choose_best_feature (data)\n",
        "        gani=perent_h-new_en  #informaion gain\n",
        "        #log(11,perent_h,new_en)\n",
        "        mask =  data[:,col] <treshold+0.00001\n",
        "    #     log(8, treshold)\n",
        "        return col , treshold, decision_tree(data[~mask],k ,new_en) ,decision_tree(data[mask],k,new_en) #,corrent_size ,gani\n",
        "      else:\n",
        "    #   if (corrent_size<k)  or (perent_h==0):\n",
        "        most_common, counter = stats.mode(data[:,0])\n",
        "\n",
        "        return most_common[0], counter[0] /len(data)\n",
        "    else: \n",
        "      if (corrent_size>k) and (perent_h>0) and (depth>1):\n",
        "        col,treshold, new_en =choose_best_feature (data)\n",
        "        gani=perent_h-new_en  #informaion gain\n",
        "\n",
        "        mask =  data[:,col] <treshold+0.00001\n",
        "\n",
        "        return col , treshold, decision_tree(data[~mask],k ,new_en, depth-1) ,decision_tree(data[mask],k,new_en, depth-1) #,corrent_size ,gani\n",
        "      else:\n",
        "\n",
        "        most_common, counter = stats.mode(data[:,0])\n",
        "\n",
        "        return most_common[0], counter[0] /len(data)\n",
        "\n",
        "  \n",
        "  def shanon_ent (a,b):\n",
        "#   log(11,\"DEBUG\",'a', a,'b', b, sep='\\n')\n",
        "    k=len(a)\n",
        "    k_n=len(b)\n",
        "    if k and k_n:\n",
        "      n=k+k_n\n",
        "      in1=k/n\n",
        "      in2=k_n/n\n",
        "      return  -1*(in1* np.log2(in1)+in2* np.log2(in2))\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def choose_best_feature (data):\n",
        "  labels=len(data.T)\n",
        "  sets = [np.unique(data.T[i,])  for i in range(labels) ]\n",
        "  tresh=  [ (s[1:]+s[:-1] )/2  for s in sets]\n",
        "  \n",
        "  ent=tresh\n",
        "  \n",
        "  \n",
        "  min_avg_ent=1 # i think the avg ent should be smaller then 1 \n",
        "  for col,t in enumerate(tresh):\n",
        "    for ind,i in enumerate(t):\n",
        "      \n",
        "      mask = data_n[:,col] < i\n",
        "      op1=data_n[mask]\n",
        "      op2=data_n[~mask]\n",
        "      \n",
        "      H_op1= shanon_ent(op1[op1[:,0]==1], op1[op1[:,0]==0])\n",
        "      H_op2= shanon_ent(op2[op2[:,0]==1], op2[op2[:,0]==0])\n",
        "#       log(11,H_op1,H_op2, tresh[0])\n",
        "     \n",
        "      len_op1=len(op1)\n",
        "      len_op2=len(op2)\n",
        "\n",
        "      ent[col][ind] = (len_op1* H_op1+len_op2* H_op2)/(len_op1+len_op2)\n",
        "      \n",
        "     \n",
        "        \n",
        "        \n",
        "      if ent[col][ind]< min_avg_ent  and col :\n",
        "        min_avg_ent=ent[col][ind]\n",
        "        min_col,min_tresh= col, i \n",
        "      \n",
        "        # if I have 2 empty groups,is it bug in recurtion?\n",
        "        \n",
        "        \n",
        "  return     min_col , min_tresh   ,min_avg_ent\n",
        "  \n",
        "    \n",
        "\n",
        "def binary_search_sheker(new, tree_tuple):\n",
        "  ''' new - a np.array simillar to original without label \n",
        "      tree_tuple- tuple of tuples - thar represent descion tree \n",
        "  '''\n",
        "  perent=tree_tuple\n",
        "  while type(tree_tuple)==tuple:\n",
        "    perent=tree_tuple\n",
        "    if new[int(tree_tuple[0]-2)]>tree_tuple[1]:\n",
        "      tree_tuple=tree_tuple[-2]\n",
        "    else:\n",
        "      tree_tuple=tree_tuple[-1]\n",
        "  return perent[0],perent[1]\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AWvhZLwTfQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class reg:\n",
        "  def __init__(self  ,degree = 10, fit_by=1 , learning_rate=1, epsilon=1E-3):\n",
        "    ''' function will do linear regression for data, it recive, degree (1),  and hot to fit polynimal (2), furier base or mixsed(3)\n",
        "        args:\n",
        "          degree - rank of polinomal / fourier base series \n",
        "          fit_by - how to do the polynomal fit \n",
        "          \n",
        "    '''\n",
        "    \n",
        "    self.epsilon=epsilon\n",
        "    self.fit_by=fit_by\n",
        "    self.learning_rate=learning_rate\n",
        "    self.DEGREE = degree*fit_by\n",
        "#     self.weigth maybe we can start with set weigth and update them ?\n",
        "    # we need to normilize the x values to predict\n",
        "    # ymin is b in the function\n",
        "   \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  def normalize(self, X, y=None):\n",
        "    ''' transfering the data to  0-1 range, keeping normlization value\n",
        "    args:\n",
        "      X-  range of fiting numpy aray\n",
        "      values prdicted or to predict by- len of x\n",
        "    \n",
        "    atributes :\n",
        "      self.miny -  min of y predicted value\n",
        "      self.minx  - min x of x given\n",
        "      self.maxy  - max y of predicted value\n",
        "      self.maxx  - max x of prdeicted value \n",
        "      \n",
        "       \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    if y is not None:\n",
        "      self.miny = np.min(y)\n",
        "      y -= self.miny\n",
        "      self.maxy = np.max(y)\n",
        "      y /= self.maxy      \n",
        "      self.minx = np.min(X)\n",
        "      self.maxx = np.max(X)\n",
        "    X -= self.minx\n",
        "    \n",
        "    X /= (self.maxx-self.minx)\n",
        "    \n",
        "    if y is not None:\n",
        "      return X.reshape(-1,1), y.reshape(-1,1)\n",
        "    else:\n",
        "      return X.reshape(-1,1)\n",
        "    \n",
        "    \n",
        "  def un_norm(self,X, y, ) :\n",
        "    ''' transfering the data from  0-1 range to the predicted range\n",
        "    args:\n",
        "      X-  range of fiting numpy aray\n",
        "      y-values prdicted or to predict by- len of x\n",
        "    \n",
        "    atributes :\n",
        "     \n",
        "    return: \n",
        "      X,y in original scale \n",
        "      \n",
        "       \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    y*=self.maxy + self.miny\n",
        "    X*=(self.maxx + self.minx)+self.minx\n",
        "    return y\n",
        "  \n",
        "  \n",
        "  def choose_model(self,xnew):\n",
        "    exp=np.arange(self.DEGREE+1)\n",
        "    # use meaningful names instead of a & b like x_col and exp_col\n",
        "    # Or reshape \"in place\"\n",
        "    \n",
        "    a=xnew.reshape(-1,1) #a.shape (1000, 1)\n",
        "\n",
        "\n",
        "#     print('a.shape', a.shape)\n",
        "    \n",
        "    b=exp.reshape(1,-1)\n",
        "#     print('b.shape', b.shape) b.shape (1, 11)\n",
        "    \n",
        "    pol=a**b\n",
        "#     print( 'pol ' ,pol.shape)  pol  (1000, 11)\n",
        "    f_base= np.hstack((  np.ones(len(a)).reshape(-1,1) , np.cos(2*np.pi *b*a) ,  np.sin(2*np.pi *b*a))  )\n",
        "    model = np.hstack (( self.fit_by%2*pol, self.fit_by//2*f_base))\n",
        "    \n",
        "#     self.model =model[ ~np.all(model == 0, axis=0)] # maybe axis 1?\n",
        "    # Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6 is different from 19)\n",
        "    if self.fit_by == 1:\n",
        "      self.model=pol\n",
        "    elif self.fit_by == 2 :\n",
        "      self.model=f_base\n",
        "    else:\n",
        "      self.model=model\n",
        "      \n",
        "  \n",
        "    \n",
        "    \n",
        "  def predict (self, x ):\n",
        "#     ypred = np.matmul(self.model ,self.weigths )\n",
        "    xnorm = self.normalize ( x )\n",
        "    \n",
        "    \n",
        "    \n",
        "    ypred=np.matmul(self.model,self.weigths)\n",
        "    print(self.weigths)\n",
        "    \n",
        "   \n",
        "    return self.un_norm(xnorm,ypred)\n",
        "    \n",
        "  def fit (self, X, y)   :\n",
        "    self.choose_model(X)\n",
        "    \n",
        "    \n",
        "    self.weigths = np.random.uniform(-0.1,0.1, self.fit_by * self.DEGREE +1).reshape(-1,1) #(11,1)\n",
        "    print('1',self.weigths, self.weigths.shape)\n",
        "    x_new , y_new=self.normalize(X,y) # (1000,1)\n",
        "    print(x_new.shape, y_new.shape)\n",
        "    \n",
        "    i=0\n",
        "    w_old=self.weigths.copy()\n",
        "     \n",
        "    \n",
        "    while i<10**4:   # we want to cuntinue until break\n",
        "      i+=1\n",
        "      pred = np.matmul( self.model ,self.weigths )\n",
        "      \n",
        "    \n",
        "      delta = y_new - pred\n",
        " \n",
        "\n",
        "      derr =- delta * self.model #error derivative \n",
        "     \n",
        "      av_d = derr.mean(axis=0).reshape(-1,1)\n",
        "#       print(av_d, self.weigths)\n",
        "\n",
        "      self.weigths -= av_d \n",
        "  \n",
        "  ##  I removed the learning rate yet it still can't find why it reaches nan and inf .\n",
        "  \n",
        "#   * self.learning_rate # not importent when we normlize to mul in learning rate\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "      if i%2000==0:\n",
        "    #     w_old+=weigths\n",
        "    #     w_new=weigths.copy()\n",
        "#         print('2',self.weigths, self.weigths.shape)\n",
        "  \n",
        "\n",
        "        if np.sum(( self.weigths-w_old ) **2) < self.epsilon:  #equel to error\n",
        "#           self.weigths = weigths\n",
        "          break\n",
        "        else:\n",
        "          w_old = self.weigths.copy()\n",
        "      \n",
        "    \n",
        "\n",
        "  \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHpSngqKF5J3",
        "colab_type": "code",
        "outputId": "fd07ff79-c3e3-4acf-9372-a6074dd674a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "\n",
        "SAMPLE_COUNT = int(1E3)\n",
        "COEF = 1E-2\n",
        "a = np.random.rand(SAMPLE_COUNT);\n",
        "b = np.sin(COEF * np.cumsum(1 / (a - a.mean())))\n",
        "c = np.cumsum(b - b.mean())\n",
        "NOISE = 2E-1\n",
        "y = c + NOISE * np.random.rand(SAMPLE_COUNT)\n",
        "y /= np.random.rand()\n",
        "y -= 1 / np.random.rand()\n",
        "X = np.arange(SAMPLE_COUNT) + np.random.rand(SAMPLE_COUNT)\n",
        "X /= np.random.rand() * SAMPLE_COUNT\n",
        "X -= 1 / np.random.rand()\n",
        "\n",
        "x=reg()\n",
        "x.fit(X,y)\n",
        "y_pred=x.predict(X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [[-0.00986859]\n",
            " [ 0.00927483]\n",
            " [ 0.04615164]\n",
            " [ 0.07450988]\n",
            " [-0.09689541]\n",
            " [ 0.07752343]\n",
            " [-0.09195751]\n",
            " [ 0.01545022]\n",
            " [-0.00235968]\n",
            " [ 0.02540244]\n",
            " [-0.0187248 ]] (11, 1)\n",
            "(1000, 1) (1000, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: overflow encountered in matmul\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in matmul\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:139: RuntimeWarning: overflow encountered in multiply\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YncrmfbkKNWz",
        "colab_type": "code",
        "outputId": "559d71a0-3c08-4495-d440-2a452b1520c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "type(y_pred)\n",
        "y_pred.shape\n",
        "# X.shape\n",
        "# y.shape\n",
        "# from matplotlib import pyplot as plt\n",
        "# plt.figure(num=None, figsize=(10, 10), dpi=80)\n",
        "# # plt.scatter(X, y, s=1)\n",
        "# plt.plot(X, y_pred)\n",
        "y_pred[0:5]\n",
        "# y[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan],\n",
              "       [nan]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Bj4Drjrqsq",
        "colab_type": "code",
        "outputId": "feb3061b-bdd1-4db7-e410-9b44218be169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "SAMPLES = 10\n",
        "apps = ['Pokemon', 'Whatsapp', 'Monday']\n",
        "columns = ['App', 'Gender', 'Age']\n",
        "favorite_app = np.array([\n",
        "np.random.randint(2, size=SAMPLES),\n",
        "np.random.randint(3, size=SAMPLES),\n",
        "np.random.normal(35, 10, size=10).astype(int)\n",
        "]).T\n",
        "\n",
        "l=favorite_app[:,0]\n",
        "d=favorite_app[:,1:]\n",
        "x=Dtree(3)\n",
        "x.predict(l,d )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e6ef95731fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfavorite_app\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfavorite_app\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9EqVR3N2Qf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}